{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth, DBSCAN, OPTICS\n",
    "\n",
    "import infoStructure as ins\n",
    "import helpers as hp\n",
    "import clustering as cl\n",
    "import display as dp\n",
    "import importlib #importlib.reload(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Point to the directories (output for the processed mat files and where the mat files reside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTDir = '' # the directory where the all the patients are (RS1000, RS10001...)\n",
    "OUTPUTDir = '' # the directory where to save all the created files\n",
    "# also, the variables to get from .mat files used all along the study\n",
    "color_iter = itertools.cycle(['navy', 'turquoise', 'cornflowerblue', 'darkorange', 'gold', \n",
    "                              'tomato', 'crimson', 'darkslategray', 'springgreen', 'chocolate'])\n",
    "titles = ['vectorRRKLD', 'vectorFAmpKLD', 'vectorUFAmpKLD', 'vectorCorrKLD'] \n",
    "feat_dict = None\n",
    "df_ALL = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Grab all the patients directory that you need, and the specific features from the 34\n",
    "\n",
    "<span style=\"color:red\">Just needed to extract information. If needed, remove the tripple quotes</span>\n",
    "```python\n",
    "\"\"\" commented code \"\"\"\n",
    "```\n",
    "\n",
    "> /!\\ ATENTION: in the \"addAllPatientsInfoV4\" script, the most suitable variable for scalable data is to_hdf = True, because it won't saturate RAM, even though, it's bigger than feather in ROM and takes more time on loading. \n",
    "\n",
    "> Because of this, the recommended way to do this is to extract [100] patients (as quantities) and since they are taken randomly from the source, this would help, afterwards around 75% from this info should be extracted to do the further calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ins)\n",
    "# files to save (of 5, and 10 and 50 ... patients inside)\n",
    "quantities = [5, 20, 50, 100] #[5, 10, 50, 100, 200] # max num of patients = 524\n",
    "## randomly\n",
    "ins.addAllPatientsInfoV4(INPUTDir, titles, quantities, OUTPUTDir, to_hdf=True)\n",
    "\n",
    "## in order, starting from N # of directory, qty = number of directories\n",
    "#qty = 10\n",
    "#start_from = 0\n",
    "#feat_dict = ins.addAllPatientsInfoV3(INPUTDir, titles, qty, start_from)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grab the information previously treated and saved as a feather file **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_file = '100_f32.h5' #'550_32.feather'\n",
    "\n",
    "# if the information has been grabed from previous cell (from patients input files)\n",
    "#df_ALL = hp.convertDictInDF(feat_dict)\n",
    "df_ALL = hp.readFileToPandas(OUTPUTDir + name_of_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ALL.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ALL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** According to the quantity of the memory available, grab randomly the rows for the study of the data **\n",
    "> 0.22 (22%) for a 16Go RAM memory avaliable computer, for one model\n",
    "\n",
    "> 0.16 for a 16Go RAM memory available computer, for running several models (like GMM but several times to get the best BIC score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DIV, indexes = hp.getRandomRows(df_ALL, 0.5)\n",
    "df_DIV, df_info = hp.cleanDF(df_DIV, ['paths', 'voie_num']) # divide DF between pure info and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DIV = cl.cleanData(df_DIV, 'mean') # impute non available data in the columns using a strategy (mean, median, most_frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dependign if PCA wants to be applied, run one or the other, in this step, removing outliers and normalization takes place\n",
    "\n",
    "> Besides, in order to do a hard removal for the difficult \"vectorUFAmpKLD\" feature removal, choose v3=True for the runOutNormV2, else, if just wanted it to be handled with the meanshift appraoch, use v3=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nout, Xnorm, std, indexes2 = cl.runOutNormV2(df_DIV, indexes, threshold=20, threshold_hard=0.01, v3=True)\n",
    "## for PCA run this one\n",
    "#df_nout, Xnorm, Xpca, dfPca, titPca, pca, std, indexes2 = cl.runOutNormPCAV2(df_DIV, indexes, threshold=20, threshold_hard=0.01, cols_hard=[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> declare which matrix of data should be used for the models according to the previous choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xnorm # Xnorm or Xpca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> print data as obtained from preprocessing, \n",
    " ```python\n",
    "if Xpca, the \"titPca\" variable should be passed,\n",
    "else titles of columns should be passed (['vectorRRKLD', 'vectorFAmpKLD', 'vectorUFAmpKLD', 'vectorCorrKLD'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dp.printPCAScatter(df_nout, titles)\n",
    "del df_nout; gc.collect()\n",
    "# del dfPca; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "```python \n",
    "if used v3=False for the preprorcessing step (runOutNormV2 function), components should be around 8 and 10\n",
    "else components are around 6 and 8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=7, covariance_type='full', random_state=0).fit(X)\n",
    "#gmm10 = GaussianMixture(n_components=10, covariance_type='full').fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ** TO PRINT**\n",
    "\n",
    "```python\n",
    "# for 2d prinring of all clusters together (6 images), use: \n",
    "dp.printPCAGMM(gmm_to_print, X, titles, color_iter)\n",
    "# for 2d printing of one cluster, use next: \n",
    "# ( gmm, gmm.predict(X), cluster #, column_1_to_display, column_2_to_display, color_of_cluster, titles )\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "dp.plotOneGMMCluster(ax, X, predicted, 0, 0, 1, 'turquoise', titles)\n",
    "# for 3d printing of onw cluster, use next: \n",
    "# ( 3dfig, gmm, gmm.predict(X), cluster #, column_1_to_display, column_2_to_display, column_3_to_display, color_of_cluster, titles)\n",
    "ax = plt.axes(projection='3d') # just once!!\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 2, 0, 1, 2, 'turquoise', titles)\n",
    "# to print all 6 possible combinations \n",
    "dp.plotAll2DGMMs(X, predicted, 1, 'turquoise', titles)\n",
    "```\n",
    "\n",
    "> <span style=\"color:red\">put one plot by cell, if not, dynamic display wont appear for each plot</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_to_print = gmm\n",
    "predicted = gmm_to_print.predict(X)\n",
    "print(hp.getRepresentativeness(gmm_to_print, X, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Extract the desired data from a cluster, complemented with its information</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_of_rows = 5\n",
    "cluster = 0\n",
    "desired_data = hp.getFromClusterInfo(X, predicted, quantity_of_rows, indexes2, cluster, df_info, titles)\n",
    "desired_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** For each cluster, and for different features, the next cell chould be modified taking into accunt the variables mentioned above ** \n",
    "\n",
    "*Since just one cluster colored by 2 cells considering 4 dimensions, 2 plots must be donne to show each cluster according the 4 dimensions in a 3d plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "dp.plotAll2DGMMs(X, predicted, 0, 'red', titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "dp.plotAll2DGMMs(X, predicted, 1, 'red', titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "\n",
    "### 3D MANIPULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show a dinamic view \"%matplotlib notebook\" , if not desired, use \"%matplotlib inline\"\n",
    "%matplotlib inline \n",
    "ax = plt.axes(projection='3d')\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 0, 0, 1, 2, 'turquoise', titles)\n",
    "plt.show(); plt.clf(); plt.close(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 0, 2, 3, 1, 'red', titles)\n",
    "plt.show(); #plt.clf(); plt.close(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 1, 2, 0, 3, 'red', titles)\n",
    "plt.show(); plt.clf(); plt.close(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 2, 1, 2, 3, 'turquoise', titles)\n",
    "plt.show(); plt.clf(); plt.close(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 2, 2, 1, 3, 'turquoise', titles)\n",
    "plt.show(); plt.clf(); plt.close(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show a dinamic view \"%matplotlib notebook\" , if not desired, use \"%matplotlib inline\"\n",
    "%matplotlib inline \n",
    "ax = plt.axes(projection='3d')\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 3, 0, 2, 3, 'turquoise', titles)\n",
    "plt.show(); plt.clf(); plt.close(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 4, 0, 1, 2, 'turquoise', titles)\n",
    "plt.show(); plt.clf(); plt.close(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 5, 0, 2, 3, 'turquoise', titles)\n",
    "plt.show(); plt.clf(); plt.close(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 6, 0, 2, 3, 'turquoise', titles)\n",
    "plt.show(); plt.clf(); plt.close(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "dp.plotOneGMMCluster3D(ax, X, predicted, 1, 0, 1, 2, 'turquoise', titles)\n",
    "plt.show(); plt.clf(); plt.close(); gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand de BIC (Bayesian Information Criterion) Optional\n",
    "> If runned, take into account the percentage of data from the total, for a 16Go computer it will only support 15% og the 120 million rows with 4 features in float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n_components_range = range(5, 12)\n",
    "best_gmm, bic, cv_types = cl.getBestGMMUsingBIC(X, n_components_range, ['full'], 0.1)\n",
    "bic = np.array(bic)\n",
    "color_iter = itertools.cycle(['navy', 'turquoise', 'cornflowerblue', 'darkorange', 'gold', 'tomato', 'crimson', 'darkslategray', 'springgreen', 'chocolate'])\n",
    "dp.plotBICScores(bic, cv_types, color_iter, n_components_range)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bita6748a10fd904a55b24d331e21814786"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
